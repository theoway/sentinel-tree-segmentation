{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2154a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchvision import transforms\n",
    "from scipy.ndimage import zoom\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "\n",
    "from shapely.geometry import box\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "from shapely.ops import unary_union\n",
    "from fiona.crs import from_epsg\n",
    "import os\n",
    "import numpy as np\n",
    "from geopy.distance import geodesic\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "from sentinelhub import SentinelHubRequest, SentinelHubDownloadClient, BBox, CRS, DataCollection, MimeType, SHConfig\n",
    "from dotenv import load_dotenv\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dda5395",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, out_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0804443c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model\n",
    "model = UNet(13, 1)\n",
    "model.load_state_dict(torch.load(\"unet_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "091bc5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate square boxes from geojson\n",
    "\n",
    "def meters_to_degrees(meters, latitude):\n",
    "    # Calculate the distance per degree at the specified latitude\n",
    "    meters_per_degree = geodesic((latitude, 0), (latitude + 1, 0)).meters\n",
    "\n",
    "    # Convert meters to degrees\n",
    "    degrees = meters / meters_per_degree\n",
    "\n",
    "    return degrees\n",
    "\n",
    "def get_bounds(geometry):\n",
    "    coords = np.array(list(geojson.utils.coords(geometry)))\n",
    "    return coords[:,0].min(), coords[:,0].max(), coords[:,1].min(), coords[:,1].max()\n",
    "\n",
    "def generate_bounding_boxes(geojson_path, box_size):\n",
    "    \"\"\"\n",
    "    Generate fixed-sized square bounding boxes inside the polygons of a GeoJSON file.\n",
    "\n",
    "    Parameters:\n",
    "    - geojson_path: Path to the GeoJSON file\n",
    "    - box_size: Size of the square bounding boxes\n",
    "\n",
    "    Returns:\n",
    "    - List of Shapely Polygon objects representing the bounding boxes\n",
    "    \"\"\"\n",
    "    # Open the GeoJSON file and get its polygons\n",
    "    bounding_boxes = []\n",
    "    \n",
    "\n",
    "    gdf = gpd.read_file(geojson_path)\n",
    "    \n",
    "    for i, polygon in enumerate(gdf.geometry):\n",
    "        avg_lat = polygon.centroid.y\n",
    "        box_size_deg = meters_to_degrees(box_size, avg_lat)\n",
    "\n",
    "        # Calculate the bounding box\n",
    "        bounds = polygon.bounds\n",
    "        num_boxes_x = int((bounds[2] - bounds[0]) // box_size_deg)\n",
    "        num_boxes_y = int((bounds[3] - bounds[1]) // box_size_deg)\n",
    "        \n",
    "        for j in range(num_boxes_x):\n",
    "            for k in range(num_boxes_y):\n",
    "                min_x = bounds[0] + j * box_size_deg\n",
    "                min_y = bounds[1] + k * box_size_deg\n",
    "                max_x = min_x + box_size_deg\n",
    "                max_y = min_y + box_size_deg\n",
    "\n",
    "                box_geometry = box(min_x, min_y, max_x, max_y)\n",
    "\n",
    "                # Check if the box is completely within the polygon\n",
    "                if polygon.contains(box_geometry):\n",
    "                    \n",
    "                    bounding_boxes.append(box_geometry)\n",
    "\n",
    "    return bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78ed2807",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounding_boxes = generate_bounding_boxes(\"../data/bbox/bbox_1.json\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95444643",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<POLYGON ((139.813 -18.539, 139.813 -18.53, 139.804 -18.53, 139.804 -18.539,...>,\n",
       " <POLYGON ((139.813 -18.53, 139.813 -18.521, 139.804 -18.521, 139.804 -18.53,...>,\n",
       " <POLYGON ((139.813 -18.521, 139.813 -18.512, 139.804 -18.512, 139.804 -18.52...>,\n",
       " <POLYGON ((139.822 -18.539, 139.822 -18.53, 139.813 -18.53, 139.813 -18.539,...>,\n",
       " <POLYGON ((139.822 -18.53, 139.822 -18.521, 139.813 -18.521, 139.813 -18.53,...>,\n",
       " <POLYGON ((139.822 -18.521, 139.822 -18.512, 139.813 -18.512, 139.813 -18.52...>,\n",
       " <POLYGON ((139.831 -18.539, 139.831 -18.53, 139.822 -18.53, 139.822 -18.539,...>,\n",
       " <POLYGON ((139.831 -18.53, 139.831 -18.521, 139.822 -18.521, 139.822 -18.53,...>,\n",
       " <POLYGON ((139.831 -18.521, 139.831 -18.512, 139.822 -18.512, 139.822 -18.52...>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "104b84d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_crs = from_epsg(4326)    \n",
    "gdf = gpd.GeoDataFrame(geometry=bounding_boxes, crs=target_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f505b1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_file('bounding_boxes_for_preds.geojson', driver='GeoJSON') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e6ccd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = (512, 512)\n",
    "time_interval = \"2023-08-30\", \"2023-08-31\"\n",
    "load_dotenv()\n",
    "\n",
    "config = SHConfig()\n",
    "config.sh_client_id = os.getenv(\"CLIENT_ID\")\n",
    "config.sh_client_secret = os.getenv(\"CLIENT_SECRET\")\n",
    "\n",
    "def getL2A():\n",
    "    evalscript_true_color =\"\"\"//VERSION=3\n",
    "\n",
    "    function setup() {\n",
    "        return {\n",
    "            input: [{\n",
    "                bands: [\"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B8A\", \"B09\", \"B11\", \"B12\", \"CLM\", \"dataMask\"],\n",
    "            }],\n",
    "            output: {\n",
    "                bands: 11\n",
    "            }\n",
    "        };\n",
    "    }\n",
    "\n",
    "    function evaluatePixel(sample) {\n",
    "        if (sample.dataMask != 1) {\n",
    "            return [99, 99, 99]\n",
    "        }\n",
    "        return [\n",
    "            2.5 * sample.B02,\n",
    "            2.5 * sample.B03,\n",
    "            2.5 * sample.B04,\n",
    "            2.5 * sample.B05,\n",
    "            2.5 * sample.B06,\n",
    "            2.5 * sample.B07,\n",
    "            2.5 * sample.B8A,\n",
    "            2.5 * sample.B09,\n",
    "            2.5 * sample.B11,\n",
    "            2.5 * sample.B12,\n",
    "            sample.CLM,\n",
    "        ];\n",
    "    }\"\"\"\n",
    "\n",
    "\n",
    "    request = SentinelHubRequest(\n",
    "        data_folder = data_folder,\n",
    "        evalscript=evalscript_true_color,\n",
    "        input_data=[\n",
    "            SentinelHubRequest.input_data(\n",
    "                data_collection=DataCollection.SENTINEL2_L2A,\n",
    "                time_interval=time_interval,\n",
    "                mosaicking_order=\"leastCC\",\n",
    "    \n",
    "            )\n",
    "        ],\n",
    "        responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n",
    "        bbox=bbox,\n",
    "        size=size,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    image = request.get_data()[0]\n",
    "    \n",
    "    return image\n",
    "\n",
    "def getDEM():\n",
    "    evalscript_true_color = \"\"\"\n",
    "    //VERSION=3\n",
    "\n",
    "    function setup() {\n",
    "        return {\n",
    "            input: [{\n",
    "                bands: [\"DEM\"]\n",
    "            }],\n",
    "            output: {\n",
    "                bands: 1,\n",
    "                sampleType: \"FLOAT32\" \n",
    "            }\n",
    "        };\n",
    "    }\n",
    "\n",
    "    function evaluatePixel(sample) {\n",
    "        return [sample.DEM];\n",
    "    }\n",
    "    \"\"\"\n",
    "\n",
    "    request = SentinelHubRequest(\n",
    "        data_folder = data_folder,\n",
    "        evalscript=evalscript_true_color,\n",
    "        input_data=[\n",
    "            SentinelHubRequest.input_data(\n",
    "                data_collection=DataCollection.DEM,\n",
    "                time_interval=time_interval,\n",
    "                mosaicking_order=\"leastCC\"\n",
    "\n",
    "            )\n",
    "        ],\n",
    "        responses=[SentinelHubRequest.output_response(\"default\", MimeType.TIFF)],\n",
    "        bbox=bbox,\n",
    "        size=size,\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    dem = request.get_data()[0]\n",
    "    return dem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "065f63df",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bounding_boxes_for_preds.geojson\") as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e90d6ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Sentinel 2 Bands...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:43<00:00,  4.80s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"Downloading Sentinel 2 Bands...\")\n",
    "root = \"../preds\"\n",
    "if not os.path.isdir(root):\n",
    "    os.mkdir(root)\n",
    "data_folder = \"../preds/bboxes\"\n",
    "if not os.path.isdir(data_folder):\n",
    "    os.mkdir(data_folder)\n",
    "for i in tqdm(range(len(data['features']))):\n",
    "    coords = data['features'][i]['geometry']['coordinates'][0]\n",
    "    bl = (min(row[0] for row in coords), min(row[1] for row in coords))\n",
    "    tr = (max(row[0] for row in coords), max(row[1] for row in coords))\n",
    "    \n",
    "    bbox = BBox((bl, tr), crs=CRS.WGS84)  \n",
    "    \n",
    "    image = getL2A()\n",
    "    dem = getDEM()\n",
    "    sub = (image[..., 3] - image[..., 2]).astype(float)\n",
    "    add = (image[..., 3] + image[..., 2]).astype(float)\n",
    "    ndvi = np.divide(sub, add, out = np.zeros_like(add) - 1, where = add != 0)\n",
    "    ndvi = np.clip(ndvi, -1, 1)\n",
    "    dem3 = dem[:, :, np.newaxis]\n",
    "    ndvi3 = ndvi[:, :, np.newaxis]\n",
    "    \n",
    "    final_image = np.concatenate((image, dem3, ndvi3), axis = -1)\n",
    "    np.save(data_folder + \"/{iid}.npy\".format(iid = i), final_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c44699e",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_bboxes_path = '../preds/bboxes/'\n",
    "preds_bboxes_npy_path = [os.path.join(preds_bboxes_path, file) for file in os.listdir(preds_bboxes_path) if file.endswith(\".npy\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0269ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../preds/bboxes/0.npy',\n",
       " '../preds/bboxes/1.npy',\n",
       " '../preds/bboxes/2.npy',\n",
       " '../preds/bboxes/3.npy',\n",
       " '../preds/bboxes/4.npy',\n",
       " '../preds/bboxes/5.npy',\n",
       " '../preds/bboxes/6.npy',\n",
       " '../preds/bboxes/7.npy',\n",
       " '../preds/bboxes/8.npy']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_bboxes_npy_path = sorted(preds_bboxes_npy_path)\n",
    "preds_bboxes_npy_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4179d9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(array, target_size):\n",
    "    zoom_factors = [target_size[i] / array.shape[i] for i in range(2)]\n",
    "    zoom_factors.append(1)\n",
    "\n",
    "    interpolated_array = zoom(array, zoom_factors, order=1, mode='nearest')\n",
    "\n",
    "    return interpolated_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9f25dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(13, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model eval\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ce0148a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_tif(array, output_path, metadata):\n",
    "    with rasterio.open(output_path, 'w', **metadata) as dst:\n",
    "        dst.write(array, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39a81b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../preds/labels\"\n",
    "if not os.path.isdir(data_folder):\n",
    "    os.mkdir(data_folder)\n",
    "\n",
    "for i, path in enumerate(preds_bboxes_npy_path):    \n",
    "    im = np.load(path)\n",
    "    im = im.astype(np.float32)\n",
    "    im = interpolate(im, (512, 512))\n",
    "    im[..., 0 : 3] /= 255\n",
    "    im = np.reshape(im, (1, 13, 512, 512))\n",
    "    im = torch.from_numpy(im)\n",
    "    with torch.no_grad():\n",
    "        predicted_output = model(im)\n",
    "\n",
    "    res = predicted_output.numpy()\n",
    "    res = np.reshape(res, (512, 512))\n",
    "    metadata = {\n",
    "        'driver': 'GTiff',\n",
    "        'count': 1,\n",
    "        'dtype': 'float32',\n",
    "        'width': res.shape[1],\n",
    "        'height': res.shape[0],\n",
    "        'crs': 'EPSG:4326',  \n",
    "        'transform': from_origin(0, 0, 1, 1),  \n",
    "    }\n",
    "    save_as_tif(res, f\"../preds/labels/{i}.tif\", metadata)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3821f72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
